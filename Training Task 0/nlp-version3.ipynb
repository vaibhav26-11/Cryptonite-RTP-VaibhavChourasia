{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14798483,"sourceType":"datasetVersion","datasetId":9461962},{"sourceId":14798569,"sourceType":"datasetVersion","datasetId":9462030},{"sourceId":14808456,"sourceType":"datasetVersion","datasetId":9469181}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install vaderSentiment\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T13:35:37.950221Z","iopub.execute_input":"2026-02-11T13:35:37.950479Z","iopub.status.idle":"2026-02-11T13:35:42.242728Z","shell.execute_reply.started":"2026-02-11T13:35:37.950443Z","shell.execute_reply":"2026-02-11T13:35:42.241776Z"}},"outputs":[{"name":"stdout","text":"Collecting vaderSentiment\n  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\nRequirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from vaderSentiment) (2.32.5)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->vaderSentiment) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->vaderSentiment) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->vaderSentiment) (2.6.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->vaderSentiment) (2026.1.4)\nDownloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: vaderSentiment\nSuccessfully installed vaderSentiment-3.3.2\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nimport pickle\nimport torch\nimport torch.nn as nn\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import f1_score, confusion_matrix\nfrom sklearn.model_selection import train_test_split\n\nfrom tokenizers import Tokenizer\nfrom tokenizers.models import BPE\nfrom tokenizers.trainers import BpeTrainer\nfrom tokenizers.pre_tokenizers import Whitespace\n\nfrom imblearn.over_sampling import SMOTE\n\nimport pandas as pd\nimport nltk\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\n\nnltk.download(\"vader_lexicon\")\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-11T13:36:03.563717Z","iopub.execute_input":"2026-02-11T13:36:03.564361Z","iopub.status.idle":"2026-02-11T13:36:09.214877Z","shell.execute_reply.started":"2026-02-11T13:36:03.564320Z","shell.execute_reply":"2026-02-11T13:36:09.214092Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package vader_lexicon to\n[nltk_data]     /usr/share/nltk_data...\n[nltk_data]   Package vader_lexicon is already up-to-date!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"WIKI_PATH = \"/kaggle/input/wiki-data/AllCombined.txt\"\n\nwiki_sentences = []\nwith open(WIKI_PATH, \"r\", encoding=\"utf-8\") as f:\n    for line in f:\n        if line.strip():\n            wiki_sentences.append(line.strip().lower())\n        if len(wiki_sentences) == 50000:\n            break\n\nprint(\"Loaded Wikipedia sentences:\", len(wiki_sentences))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T13:36:51.014980Z","iopub.execute_input":"2026-02-11T13:36:51.015581Z","iopub.status.idle":"2026-02-11T13:36:51.294490Z","shell.execute_reply.started":"2026-02-11T13:36:51.015554Z","shell.execute_reply":"2026-02-11T13:36:51.293890Z"}},"outputs":[{"name":"stdout","text":"Loaded Wikipedia sentences: 50000\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"tokenizer = Tokenizer(BPE(unk_token=\"<unk>\"))\ntokenizer.pre_tokenizer = Whitespace()\n\ntrainer = BpeTrainer(\n    vocab_size=10000,\n    special_tokens=[\"<pad>\", \"<unk>\"]\n)\n\ntokenizer.train_from_iterator(wiki_sentences, trainer=trainer)\n\nprint(\"BPE vocab size:\", tokenizer.get_vocab_size())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T13:37:02.115640Z","iopub.execute_input":"2026-02-11T13:37:02.115988Z","iopub.status.idle":"2026-02-11T13:37:03.929469Z","shell.execute_reply.started":"2026-02-11T13:37:02.115960Z","shell.execute_reply":"2026-02-11T13:37:03.928754Z"}},"outputs":[{"name":"stdout","text":"\n\n\nBPE vocab size: 10000\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"class CBOWDataset(Dataset):\n    def __init__(self, sentences, tokenizer, window_size=5):\n        self.data = []\n        for sent in sentences:\n            ids = tokenizer.encode(sent).ids\n            for i in range(window_size, len(ids) - window_size):\n                context = ids[i-window_size:i] + ids[i+1:i+window_size+1]\n                target = ids[i]\n                self.data.append((context, target))\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        ctx, tgt = self.data[idx]\n        return torch.tensor(ctx), torch.tensor(tgt)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T13:37:16.473790Z","iopub.execute_input":"2026-02-11T13:37:16.474125Z","iopub.status.idle":"2026-02-11T13:37:16.479618Z","shell.execute_reply.started":"2026-02-11T13:37:16.474098Z","shell.execute_reply":"2026-02-11T13:37:16.478916Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class CBOW(nn.Module):\n    def __init__(self, vocab_size, embed_dim=384):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, embed_dim)\n\n    def forward(self, x):\n        return self.emb(x).mean(dim=1)\n\n\nclass NegativeSamplingLoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n    def forward(self, ctx_vec, tgt_vec, neg_vecs):\n        pos = torch.sum(ctx_vec * tgt_vec, dim=1)\n        neg = torch.bmm(neg_vecs, ctx_vec.unsqueeze(2)).squeeze(2)\n\n        pos_loss = torch.nn.functional.logsigmoid(pos)\n        neg_loss = torch.nn.functional.logsigmoid(-neg).sum(dim=1)\n\n        return -(pos_loss + neg_loss).mean()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T13:37:25.680717Z","iopub.execute_input":"2026-02-11T13:37:25.681084Z","iopub.status.idle":"2026-02-11T13:37:25.687048Z","shell.execute_reply.started":"2026-02-11T13:37:25.681049Z","shell.execute_reply":"2026-02-11T13:37:25.686257Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"dataset = CBOWDataset(wiki_sentences, tokenizer, window_size=5)\nloader = DataLoader(dataset, batch_size=128, shuffle=True)\n\nvocab_size = tokenizer.get_vocab_size()\nmodel = CBOW(vocab_size).to(device)\nloss_fn = NegativeSamplingLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\nfor epoch in range(5):\n    for ctx, tgt in loader:\n        ctx, tgt = ctx.to(device), tgt.to(device)\n\n        ctx_vec = model(ctx)\n        tgt_vec = model.emb(tgt)\n\n        neg_ids = torch.randint(0, vocab_size, (ctx.size(0), 5)).to(device)\n        neg_vecs = model.emb(neg_ids)\n\n        loss = loss_fn(ctx_vec, tgt_vec, neg_vecs)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    print(f\"Epoch {epoch+1}/5 done\")\n\ntorch.save(model.emb.weight.detach(), \"cbow_embeddings.pt\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T13:37:57.639427Z","iopub.execute_input":"2026-02-11T13:37:57.640042Z","iopub.status.idle":"2026-02-11T13:42:50.106040Z","shell.execute_reply.started":"2026-02-11T13:37:57.640015Z","shell.execute_reply":"2026-02-11T13:42:50.105351Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/5 done\nEpoch 2/5 done\nEpoch 3/5 done\nEpoch 4/5 done\nEpoch 5/5 done\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# -------- REPLACEMENT CELL 7 --------\n\nPHRASEBANK_PATH = \"/kaggle/input/fin-data/Sentences_50Agree.txt\"\n\ndf = pd.read_csv(\n    PHRASEBANK_PATH,\n    sep=\"@\",\n    header=None,\n    names=[\"sentence\", \"sentiment\"],\n    encoding=\"latin-1\"\n)\n\ndf[\"sentiment\"] = df[\"sentiment\"].str.strip().str.lower()\n\nlabel_map = {\n    \"negative\": 0,\n    \"neutral\": 1,\n    \"positive\": 2\n}\n\ndf[\"label\"] = df[\"sentiment\"].map(label_map)\n\n# REMOVE DUPLICATES BEFORE SPLIT\ndf = df.drop_duplicates(subset=\"sentence\").reset_index(drop=True)\n\nprint(\"Class distribution:\")\nprint(df[\"sentiment\"].value_counts())\nprint(\"Dataset size:\", len(df))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T14:16:52.414838Z","iopub.execute_input":"2026-02-11T14:16:52.415554Z","iopub.status.idle":"2026-02-11T14:16:52.448286Z","shell.execute_reply.started":"2026-02-11T14:16:52.415523Z","shell.execute_reply":"2026-02-11T14:16:52.447670Z"}},"outputs":[{"name":"stdout","text":"Class distribution:\nsentiment\nneutral     2872\npositive    1362\nnegative     604\nName: count, dtype: int64\nDataset size: 4838\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# -------- REPLACEMENT CELL 8 --------\n\nembeddings = torch.load(\"cbow_embeddings.pt\").cpu().numpy()\nembed_dim = embeddings.shape[1]\n\ndef document_embedding(text):\n    ids = tokenizer.encode(text.lower()).ids\n    ids = [i for i in ids if i < embeddings.shape[0]]\n\n    if len(ids) == 0:\n        return np.zeros(embed_dim)\n\n    return embeddings[ids].mean(axis=0)\n\nX = np.vstack(df[\"sentence\"].apply(document_embedding))\ny = df[\"label\"].values\n\nprint(\"NaNs in X:\", np.isnan(X).sum())\n\n\nfrom sklearn.model_selection import train_test_split\n\nindices = np.arange(len(df))\n\ntrain_idx, test_idx = train_test_split(\n    indices,\n    test_size=0.2,\n    random_state=42,\n    stratify=y\n)\n\nX_train = X[train_idx]\nX_test = X[test_idx]\ny_train = y[train_idx]\ny_test = y[test_idx]\n\nprint(\"Train size:\", len(train_idx))\nprint(\"Test size:\", len(test_idx))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T14:16:57.021251Z","iopub.execute_input":"2026-02-11T14:16:57.021528Z","iopub.status.idle":"2026-02-11T14:16:57.487388Z","shell.execute_reply.started":"2026-02-11T14:16:57.021507Z","shell.execute_reply":"2026-02-11T14:16:57.486737Z"}},"outputs":[{"name":"stdout","text":"NaNs in X: 0\nTrain size: 3870\nTest size: 968\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# -------- REPLACEMENT CELL 9 --------\n\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import f1_score, confusion_matrix\n\n# Apply SMOTE only on training\nsmote = SMOTE(random_state=42)\nX_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n\nclf = LogisticRegression(\n    max_iter=1000,\n    multi_class=\"multinomial\",\n    solver=\"lbfgs\"\n)\n\nclf.fit(X_train_resampled, y_train_resampled)\n\ny_pred = clf.predict(X_test)\n\nprint(\"CBOW + Logistic Regression (3-class)\")\nprint(\"Macro F1-score:\", f1_score(y_test, y_pred, average=\"macro\"))\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(y_test, y_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T14:17:00.227827Z","iopub.execute_input":"2026-02-11T14:17:00.228375Z","iopub.status.idle":"2026-02-11T14:17:04.483137Z","shell.execute_reply.started":"2026-02-11T14:17:00.228348Z","shell.execute_reply":"2026-02-11T14:17:04.481079Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"CBOW + Logistic Regression (3-class)\nMacro F1-score: 0.5679725271435804\nConfusion Matrix:\n[[ 76  23  22]\n [ 71 370 134]\n [ 44  81 147]]\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# -------- REPLACEMENT CELL 10 --------\n\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\n\nvader = SentimentIntensityAnalyzer()\n\nvader_preds = []\n\nfor sentence in df.iloc[test_idx][\"sentence\"]:\n    score = vader.polarity_scores(sentence)[\"compound\"]\n\n    if score >= 0.05:\n        vader_preds.append(2)\n    elif score <= -0.05:\n        vader_preds.append(0)\n    else:\n        vader_preds.append(1)\n\nprint(\"VADER Baseline (3-class)\")\nprint(\"Macro F1-score:\", f1_score(y_test, vader_preds, average=\"macro\"))\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(y_test, vader_preds))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T14:18:43.863655Z","iopub.execute_input":"2026-02-11T14:18:43.864381Z","iopub.status.idle":"2026-02-11T14:18:44.054771Z","shell.execute_reply.started":"2026-02-11T14:18:43.864350Z","shell.execute_reply":"2026-02-11T14:18:44.054213Z"}},"outputs":[{"name":"stdout","text":"VADER Baseline (3-class)\nMacro F1-score: 0.490134921250291\nConfusion Matrix:\n[[ 38  35  48]\n [ 36 293 246]\n [  9  75 188]]\n","output_type":"stream"}],"execution_count":25}]}